#based on https://benjjneb.github.io/dada2/ITS_workflow.html
# store the current directory
initial.dir<-getwd()
# change to the working directory
setwd("C:/Users/wd" )
# load the necessary libraries
library(dada2)
library(ShortRead)
library(Biostrings)
# define the path to fasta files
path <- "C:/sample" 
# Forward fastq filenames have format: .fastq
fnFs <- sort(list.files(pattern = ".fastq.gz", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), ".fastq"), `[`, 1)
#
#fix losses at filtering
setDadaOpt(OMEGA_C = 0)
# Place filtered files in filtered/ subdirectory
fnFs.filtN <- file.path(path ="./filtN", basename(fnFs)) # Put N-filterd files in filtN/ subdirectory
out <- filterAndTrim(fnFs, fnFs.filtN, maxN=5, minLen=60, multithread = FALSE)
#get error model for forward and reverse reads (slow)
errF <- learnErrors(fnFs.filtN, multithread=TRUE)
#plot to check errors sensible
plotErrors(errF, nominalQ=TRUE)
# apply the core sample inference algorithm to the filtered and trimmed sequence data.
dadaFs <- dada(fnFs.filtN, err=errF, multithread=TRUE)
#dadaFs[[1]]
#some useful stuff
seqtab <- makeSequenceTable(dadaFs)
dim(seqtab)
table(nchar(getSequences(seqtab)))
#to deal with identical overlaping sequences of different lengths
seqtab.collapse <- collapseNoMismatch(seqtab, minOverlap = 20, orderBy = "abundance", identicalOnly = FALSE, vec = TRUE, band = -1, verbose = FALSE)
#remove Chimeras
seqtab.nochim <- removeBimeraDenovo(seqtab.collapse, method="consensus", multithread=TRUE, verbose=TRUE)
#track reads through pipeline (assume multiples)
dim(seqtab.nochim)
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), rowSums(seqtab.collapse), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "collapsed", "nonchim")
rownames(track) <- sample.names
head(track)
#get taxonomy of sequences
taxa <- assignTaxonomy(seqtab.nochim, "C:/silva_nr99_taxa/silva_nr99_v138_train_set.fa.gz", tryRC = TRUE, multithread=FALSE)
taxa.print <- taxa 
#collate data and write .csv file
abundance <- as.data.frame(t(seqtab.nochim))
colnames(abundance) <- sample.names
full.print <- cbind(abundance,Sequence = colnames(seqtab.nochim),taxa.print)
write.table(full.print, file=file.path(path,"sample.csv"), sep=",", row.names=FALSE)
# unload the libraries
detach("package:dada2")
# change back to the original directory
setwd(initial.dir)
